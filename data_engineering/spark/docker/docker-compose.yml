version: "3"
services:
  spark-master:
    image: bitnami/spark:3.5.0
    container_name: spark-master
    networks:
      - spark-network
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
    ports:
      - "8080:8080"
      - "7077:7077"
      - "4040:4040"
    volumes:
      - ./../scripts:/scripts

  spark-worker-1:
    image: bitnami/spark:3.5.0
    container_name: spark-worker-1
    networks:
      - spark-network
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=16G
      - SPARK_WORKER_CORES=16

  jupyter:
    image: jupyter/pyspark-notebook
    container_name: jupyter
    networks:
      - spark-network
    environment:
      - SPARK_MASTER=spark://spark-master:7077
    ports:
      - "8888:8888"
    volumes:
      - ./../notebooks:/home/jovyan/work

  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    networks:
      - spark-network
    environment:
      - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_BROKER_ID=1
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_LOG_DIRS=/var/lib/kafka/data
      - KAFKA_TOOLS_LOG4J_LOGLEVEL=INFO
    ports:
      - "9092:9092"
    depends_on:
      - zookeeper

  zookeeper:
    image: zookeeper:3.9.3
    container_name: zookeeper
    networks:
      - spark-network
    ports:
      - "2181:2181"

  hdfs-namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: hdfs-namenode
    networks:
      - spark-network
    environment:
      - CLUSTER_NAME=test
      - CORE_CONF_fs_defaultFS=hdfs://hdfs-namenode:8020
      - NAMENODE_UI_PORT=9870
    ports:
      - "9870:9870"
    volumes:
      - hdfs-namenode:/hadoop/dfs/namenode      
      - ./../sample_data:/sample_data
    
  hdfs-datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: hdfs-datanode
    networks:
      - spark-network
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://hdfs-namenode:8020
      - DATANODE_UI_PORT=9864
    ports:
      - "9864:9864"
    volumes:
      - hdfs-datanode:/hadoop/dfs/datanode
    depends_on:
      - hdfs-namenode

volumes:
  hdfs-namenode:
    # Empty volume to persist HDFS namenode data
  hdfs-datanode:
    # Empty volume to persist HDFS datanode data

networks:
  spark-network:
    driver: bridge
